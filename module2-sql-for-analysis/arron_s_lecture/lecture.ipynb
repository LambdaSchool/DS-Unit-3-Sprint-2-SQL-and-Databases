{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitdssqlconda0c684aed25d1435d9aabd9bb377d36d3",
   "display_name": "Python 3.7.6 64-bit ('ds-sql': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Demo Code for Connecting to PostgreSQL from Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Collecting psycopg2-binary\n  Using cached psycopg2_binary-2.8.5-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\nInstalling collected packages: psycopg2-binary\nSuccessfully installed psycopg2-binary-2.8.5\n"
    }
   ],
   "source": [
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['BINARY',\n 'Binary',\n 'DATETIME',\n 'DataError',\n 'DatabaseError',\n 'Date',\n 'DateFromTicks',\n 'Error',\n 'IntegrityError',\n 'InterfaceError',\n 'InternalError',\n 'NUMBER',\n 'NotSupportedError',\n 'OperationalError',\n 'ProgrammingError',\n 'ROWID',\n 'STRING',\n 'Time',\n 'TimeFromTicks',\n 'Timestamp',\n 'TimestampFromTicks',\n 'Warning',\n '__builtins__',\n '__cached__',\n '__doc__',\n '__file__',\n '__libpq_version__',\n '__loader__',\n '__name__',\n '__package__',\n '__path__',\n '__spec__',\n '__version__',\n '_connect',\n '_ext',\n '_ipaddress',\n '_json',\n '_psycopg',\n '_range',\n 'apilevel',\n 'compat',\n 'connect',\n 'errors',\n 'extensions',\n 'extras',\n 'paramstyle',\n 'threadsafety',\n 'tz']"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "dir(psycopg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/home/joe/Desktop/school/3-2/module2-sql-for-analysis\n"
    }
   ],
   "source": [
    "import dotenv\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Help on function connect in module psycopg2:\n\nconnect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs)\n    Create a new database connection.\n    \n    The connection parameters can be specified as a string:\n    \n        conn = psycopg2.connect(\"dbname=test user=postgres password=secret\")\n    \n    or using a set of keyword arguments:\n    \n        conn = psycopg2.connect(database=\"test\", user=\"postgres\", password=\"secret\")\n    \n    Or as a mix of both. The basic connection parameters are:\n    \n    - *dbname*: the database name\n    - *database*: the database name (only as keyword argument)\n    - *user*: user name used to authenticate\n    - *password*: password used to authenticate\n    - *host*: database host address (defaults to UNIX socket if not provided)\n    - *port*: connection port number (defaults to 5432 if not provided)\n    \n    Using the *connection_factory* parameter a different class or connections\n    factory can be specified. It should be a callable object taking a dsn\n    argument.\n    \n    Using the *cursor_factory* parameter, a new default cursor factory will be\n    used by cursor().\n    \n    Using *async*=True an asynchronous connection will be created. *async_* is\n    a valid alias (for Python versions where ``async`` is a keyword).\n    \n    Any other keyword parameter will be passed to the underlying client\n    library: the list of supported parameters depends on the library version.\n\n"
    }
   ],
   "source": [
    "help(psycopg2.connect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "\n",
    "db_host=os.getenv(\"PG_HOST\")\n",
    "db_pass=os.getenv(\"PG_PASSWORD\")\n",
    "db_user=os.getenv(\"PG_USER\")\n",
    "db_port=os.getenv(\"PG_PORT\")\n",
    "db_table=os.getenv(\"PG_TABLE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=db_table,\n",
    "                        password=db_pass,\n",
    "                        user=db_user,\n",
    "                        port=db_port,\n",
    "                        host=db_host)\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<connection object at 0x7ff630a34690; dsn: 'user=qewtsapf password=xxx dbname=qewtsapf host=drona.db.elephantsql.com port=5432', closed: 0>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['DataError',\n 'DatabaseError',\n 'Error',\n 'IntegrityError',\n 'InterfaceError',\n 'InternalError',\n 'NotSupportedError',\n 'OperationalError',\n 'ProgrammingError',\n 'Warning',\n '__class__',\n '__delattr__',\n '__dir__',\n '__doc__',\n '__enter__',\n '__eq__',\n '__exit__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n 'async',\n 'async_',\n 'autocommit',\n 'binary_types',\n 'cancel',\n 'close',\n 'closed',\n 'commit',\n 'cursor',\n 'cursor_factory',\n 'deferrable',\n 'dsn',\n 'encoding',\n 'fileno',\n 'get_backend_pid',\n 'get_dsn_parameters',\n 'get_native_connection',\n 'get_parameter_status',\n 'get_transaction_status',\n 'info',\n 'isexecuting',\n 'isolation_level',\n 'lobject',\n 'notices',\n 'notifies',\n 'pgconn_ptr',\n 'poll',\n 'protocol_version',\n 'readonly',\n 'reset',\n 'rollback',\n 'server_version',\n 'set_client_encoding',\n 'set_isolation_level',\n 'set_session',\n 'status',\n 'string_types',\n 'tpc_begin',\n 'tpc_commit',\n 'tpc_prepare',\n 'tpc_recover',\n 'tpc_rollback',\n 'xid']"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# everytime you get something new its a good ide to take a look at the methods that are in it's scope\n",
    "dir(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "curs=conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new table\n",
    "query=\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS test_table \n",
    "(\n",
    "  id SERIAL PRIMARY KEY,\n",
    "  name varchar(40) NOT NULL,\n",
    "  data JSONB\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# create a new table with the cursor object\n",
    "curs.execute(query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert information into the new table\n",
    "insert_query=\"\"\"\n",
    "INSERT INTO test_table (name, data) VALUES\n",
    "('A row name', null),\n",
    "('Another row, with JSON', '{ \"a\": 1, \"b\": [\"dog\", \"cat\", 42], \"c\": true }'::JSONB);\n",
    "\"\"\"\n",
    "\n",
    "curs.execute(insert_query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "curs.execute(\"\"\"SELECT * FROM test_table;\"\"\")\n",
    "result = curs.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(1, 'A row name', None),\n (2, 'Another row, with JSON', {'a': 1, 'b': ['dog', 'cat', 42], 'c': True})]"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL - RPG data from SQLite to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ls: cannot access 'DATAPATH': No such file or directory\n"
    }
   ],
   "source": [
    "DATAPATH='data/rpg_db.sqlite3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_conn = sqlite3.connect(DATAPATH)\n",
    "sq_curs = sq_conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(302,)"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "sq_curs.execute(\"\"\"SELECT COUNT(*) FROM charactercreator_character\"\"\")\n",
    "result = sq_curs.fetchone()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our goal is to copy the character's table to apostgre using python\n",
    "# step one EXtract all of the characters\n",
    "get_characters = 'SELECT * FROM charactercreator_character'\n",
    "sq_curs.execute(get_characters)\n",
    "characters = sq_curs.fetchall()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(1, 'Aliquid iste optio reiciendi', 0, 0, 10, 1, 1, 1, 1),\n (2, 'Optio dolorem ex a', 0, 0, 10, 1, 1, 1, 1),\n (3, 'Minus c', 0, 0, 10, 1, 1, 1, 1),\n (4, 'Sit ut repr', 0, 0, 10, 1, 1, 1, 1),\n (5, 'At id recusandae expl', 0, 0, 10, 1, 1, 1, 1)]"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "characters[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(0, 'character_id', 'integer', 1, None, 1),\n (1, 'name', 'varchar(30)', 1, None, 0),\n (2, 'level', 'integer', 1, None, 0),\n (3, 'exp', 'integer', 1, None, 0),\n (4, 'hp', 'integer', 1, None, 0),\n (5, 'strength', 'integer', 1, None, 0),\n (6, 'intelligence', 'integer', 1, None, 0),\n (7, 'dexterity', 'integer', 1, None, 0),\n (8, 'wisdom', 'integer', 1, None, 0)]"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "# transform step\n",
    "# in this case there is not that much to change in the underling data\n",
    "# there isnt much getting changed its going for sql to sql\n",
    "\n",
    "# but what do we need to load into postgre?\n",
    "# going to need a new table in the destination\n",
    "# create a new table\n",
    "sq_curs.execute('PRAGMA table_info(charactercreator_character)').fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_character_table=\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS charactercreator_character (\n",
    "    character_id SERIAL PRIMARY KEY,\n",
    "    name varchar(30),\n",
    "    level INT,\n",
    "    exp INT,\n",
    "    hp INT,\n",
    "    strength INT,\n",
    "    intelligence INT,\n",
    "    dexterity INT,\n",
    "    wisdom INT\n",
    ");\n",
    "\"\"\"\n",
    "curs.execute(create_character_table)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nINSERT INTO charactercreator_character\n(name,level,exp,hp,stregth,intelligence,dexterity,wisdom)\nVALUES ('Aliquid iste optio reiciendi', 0, 0, 10, 1, 1, 1, 1)\n"
    }
   ],
   "source": [
    "insert_query=f\"\"\"\n",
    "INSERT INTO charactercreator_character\n",
    "(name,level,exp,hp,strength,intelligence,dexterity,wisdom)\n",
    "VALUES \"\"\" + str(characters[0][1:]) + \";\"\n",
    "print(insert_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to do them for all characters\n",
    "for character in characters:\n",
    "    insert_query=f\"\"\"\n",
    "    INSERT INTO charactercreator_character\n",
    "    (name,level,exp,hp,strength,intelligence,dexterity,wisdom)\n",
    "    VALUES \"\"\" + str(character[1:]) + ';'\n",
    "    curs.execute(insert_query)\n",
    "    #conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "app  arron_s_lecture  data  README.md  sql\n"
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "rpg_db.sqlite3\ttitanic.csv\n"
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH='data/titanic.csv'\n",
    "df=pd.read_csv(DATAPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Survived  Pclass                                               Name  \\\n0         0       3                             Mr. Owen Harris Braund   \n1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n2         1       3                              Miss. Laina Heikkinen   \n3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n4         0       3                            Mr. William Henry Allen   \n\n      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n0    male  22.0                        1                        0   7.2500  \n1  female  38.0                        1                        0  71.2833  \n2  female  26.0                        0                        0   7.9250  \n3  female  35.0                        1                        0  53.1000  \n4    male  35.0                        0                        0   8.0500  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Siblings/Spouses Aboard</th>\n      <th>Parents/Children Aboard</th>\n      <th>Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Mr. Owen Harris Braund</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Mrs. John Bradley (Florence Briggs Thayer) Cum...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>Miss. Laina Heikkinen</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Mrs. Jacques Heath (Lily May Peel) Futrelle</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Mr. William Henry Allen</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_character_table=\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS titanic (\n",
    "    index SERIAL PRIMARY KEY,\n",
    "    survived varchar(30),\n",
    "    pclass INT,\n",
    "    name VARCHAR(50),\n",
    "    sex VARCHAR(10),\n",
    "    age REAL,\n",
    "    siblings_Spouses_Aboard INT,\n",
    "    Parents_Children_Aboard INT,\n",
    "    Fair REAL\n",
    ");\n",
    "\"\"\"\n",
    "curs.execute(create_character_table)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Help on method to_sql in module pandas.core.generic:\n\nto_sql(name: str, con, schema=None, if_exists: str = 'fail', index: bool = True, index_label=None, chunksize=None, dtype=None, method=None) -> None method of pandas.core.frame.DataFrame instance\n    Write records stored in a DataFrame to a SQL database.\n    \n    Databases supported by SQLAlchemy [1]_ are supported. Tables can be\n    newly created, appended to, or overwritten.\n    \n    Parameters\n    ----------\n    name : str\n        Name of SQL table.\n    con : sqlalchemy.engine.Engine or sqlite3.Connection\n        Using SQLAlchemy makes it possible to use any DB supported by that\n        library. Legacy support is provided for sqlite3.Connection objects. The user\n        is responsible for engine disposal and connection closure for the SQLAlchemy\n        connectable See `here                 <https://docs.sqlalchemy.org/en/13/core/connections.html>`_\n    \n    schema : str, optional\n        Specify the schema (if database flavor supports this). If None, use\n        default schema.\n    if_exists : {'fail', 'replace', 'append'}, default 'fail'\n        How to behave if the table already exists.\n    \n        * fail: Raise a ValueError.\n        * replace: Drop the table before inserting new values.\n        * append: Insert new values to the existing table.\n    \n    index : bool, default True\n        Write DataFrame index as a column. Uses `index_label` as the column\n        name in the table.\n    index_label : str or sequence, default None\n        Column label for index column(s). If None is given (default) and\n        `index` is True, then the index names are used.\n        A sequence should be given if the DataFrame uses MultiIndex.\n    chunksize : int, optional\n        Specify the number of rows in each batch to be written at a time.\n        By default, all rows will be written at once.\n    dtype : dict or scalar, optional\n        Specifying the datatype for columns. If a dictionary is used, the\n        keys should be the column names and the values should be the\n        SQLAlchemy types or strings for the sqlite3 legacy mode. If a\n        scalar is provided, it will be applied to all columns.\n    method : {None, 'multi', callable}, optional\n        Controls the SQL insertion clause used:\n    \n        * None : Uses standard SQL ``INSERT`` clause (one per row).\n        * 'multi': Pass multiple values in a single ``INSERT`` clause.\n        * callable with signature ``(pd_table, conn, keys, data_iter)``.\n    \n        Details and a sample callable implementation can be found in the\n        section :ref:`insert method <io.sql.method>`.\n    \n        .. versionadded:: 0.24.0\n    \n    Raises\n    ------\n    ValueError\n        When the table already exists and `if_exists` is 'fail' (the\n        default).\n    \n    See Also\n    --------\n    read_sql : Read a DataFrame from a table.\n    \n    Notes\n    -----\n    Timezone aware datetime columns will be written as\n    ``Timestamp with timezone`` type with SQLAlchemy if supported by the\n    database. Otherwise, the datetimes will be stored as timezone unaware\n    timestamps local to the original timezone.\n    \n    .. versionadded:: 0.24.0\n    \n    References\n    ----------\n    .. [1] http://docs.sqlalchemy.org\n    .. [2] https://www.python.org/dev/peps/pep-0249/\n    \n    Examples\n    --------\n    \n    Create an in-memory SQLite database.\n    \n    >>> from sqlalchemy import create_engine\n    >>> engine = create_engine('sqlite://', echo=False)\n    \n    Create a table from scratch with 3 rows.\n    \n    >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n    >>> df\n         name\n    0  User 1\n    1  User 2\n    2  User 3\n    \n    >>> df.to_sql('users', con=engine)\n    >>> engine.execute(\"SELECT * FROM users\").fetchall()\n    [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]\n    \n    >>> df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})\n    >>> df1.to_sql('users', con=engine, if_exists='append')\n    >>> engine.execute(\"SELECT * FROM users\").fetchall()\n    [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),\n     (0, 'User 4'), (1, 'User 5')]\n    \n    Overwrite the table with just ``df1``.\n    \n    >>> df1.to_sql('users', con=engine, if_exists='replace',\n    ...            index_label='id')\n    >>> engine.execute(\"SELECT * FROM users\").fetchall()\n    [(0, 'User 4'), (1, 'User 5')]\n    \n    Specify the dtype (especially useful for integers with missing values).\n    Notice that while pandas is forced to store the data as floating point,\n    the database supports nullable integers. When fetching the data with\n    Python, we get back integer scalars.\n    \n    >>> df = pd.DataFrame({\"A\": [1, None, 2]})\n    >>> df\n         A\n    0  1.0\n    1  NaN\n    2  2.0\n    \n    >>> from sqlalchemy.types import Integer\n    >>> df.to_sql('integers', con=engine, index=False,\n    ...           dtype={\"A\": Integer()})\n    \n    >>> engine.execute(\"SELECT * FROM integers\").fetchall()\n    [(1,), (None,), (2,)]\n\n"
    }
   ],
   "source": [
    "help(df.to_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}